# 1.Kafka

# 一 概述
## 1 简介
快速、高可扩展、高吞吐的分布式流处理平台，配合kafka Stream，在流式数据处理中非常常用。

主要适合于两大类的应用场景：
1. 构造实时流数据管道，它可以在系统或应用之间可靠地获取数据。 (相当于message queue)
2. 构建实时流式应用程序，对这些流数据进行转换或者影响。 (就是流处理，通过kafka stream topic和topic之间内部进行变化)

那么什么是流处理平台呢：流处理平台有以下三种特性:
1. 可以让你发布和订阅流式的记录。这一方面与消息队列或者企业消息系统类似。
2. 可以储存流式的记录，并且有较好的容错性。
3. 可以在流式记录产生时就进行处理。

### 1.1 优点特点
优点如下：
1. 解耦
2. 异步
2. 削峰
3. 冗余（副本）：有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。
4. 扩展性
5. 顺序保证
6. 缓冲：在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助

特点：
1. 在Kafka中，客户端和服务器使用一个简单、高性能、支持多语言的 TCP 协议.此协议版本化并且向下兼容老版本


## 2 历史
Kafka是最初由Linkedin公司开发，于2010年贡献给了Apache基金会并成为顶级开源项目。

## 4 文档网址等
1. 官网
    1. https://kafka.apache.org/
    1. https://kafka.apachecn.org/
    3. https://kafka.apache.org/protocol

# 二 安装配置
## linux
以centos为例：
1. 先安装jdk
    
    ```bash
    yum install java-1.8.0-openjdk.x86_64 -y
    # 除了jdk还需要安装devel，因为gradle时需要tools.jar
    yum install java-1.8.0-openjdk-devel.x86_64 -y 
    ```
2. 下载kafka，去官网找到链接

    ```bash
    wget https://mirror.efect.ro/apache/kafka/2.8.0/kafka-2.8.0-src.tgz
    # 解压
    tar -xvf 
    ```
3. 启动：需要用到gradlew，否则会报错"Classpath is empty. Please build the project first e.g. by running './gradlew jar -PscalaVersion=2.13.5'"
    1. 启动zookeeper

## mac
步骤：
1. 安装zookeeper：
    1. 先安装`xcode-select --install`，在安装...
    1. 启动zookeeper： `/usr/local/Cellar/kafka/2.6.0/bin`目录下的`./zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties`，配置文件需要用绝对路径
2. 安装kafka`brew install kafka`
    4. 修改Kafka服务配置文件`/usr/local/etc/kafka/server.properties`
        2. 解除注释`listeners=PLAINTEXT://localhost:9092`：启动的host和port
    5. 启动Kafka服务`kafka-server-start /usr/local/etc/kafka/server.properties`
    
    
## 4 配置
1. 添加acl
        
    ```bash
    bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic Test-topic

    ```
2. 配置认证
    1. 为zookeeper配置JAAS:在config目录下创建文件zookeeper_jaas.conf，文件内容具体如下
            
        ```java
        Server {
            org.apache.kafka.common.security.plain.PlainLoginModule required // 加密方式，用plain, 连接时必须身份验证
            // username，password是zookeeper之间通讯的用户名和密码
            username="admin"
            password="admin"
            // user_admin="admin"的结构是user_username="password"，用户名是admin， 密码是admin，客户端连接到zookeeper时，使用这个用户名和密码。
            user_admin="admin";
        };
        ```
    2. 为broker配置JAAS:在config目录下创建文件kafka_server_jaas.conf，具体内容如下
            
        ```java
        // Client节点，是broker连接zookeeper时的认证信息
        Client {
            org.apache.kafka.common.security.plain.PlainLoginModule required
            username="admin"
            password="admin";
        };
        
        // KafkaServer节点：集群中，broker之间用节点中的username，password进行通讯
        // KafkaServer节点：客户端（producer，consumer）连接broker时用user_username="password"结构中的账号密码登录
        KafkaServer {
            org.apache.kafka.common.security.plain.PlainLoginModule required
            username="admin"
            password="admin"
            user_admin="admin"
            user_alice="alice";
        };
        ```
    3. 为客户端（producer，consumer等）配置JAAS:在config目录下创建文件kafka_client_jaas.conf，文件内容具体如下：客户端用client节点信息，连接认证zookeeper后broker
    
        ```java
        Client {
            org.apache.kafka.common.security.plain.PlainLoginModule required
            username="admin"
            password="admin";
        };
        ```
    4. zookeeper的sasl配置:修改zookeeper.properties,主要新增这么几行
            
        ```bash
        # 加密认证
        maxClientCnxns=0
        authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
        requireClientAuthScheme=sasl
        jaasLoginRenew=3600000
        ```
    5. broker的sasl配置:修改文件：server.properties
        
        ```bash
        listeners=SASL_PLAINTEXT://192.168.40.150:9091
        #使用的认证协议
        security.inter.broker.protocol=SASL_PLAINTEXT
        #SASL机制 
        sasl.enabled.mechanisms=PLAIN  
        sasl.mechanism.inter.broker.protocol=PLAIN   
        # 完成身份验证的类 
        #authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer 
        # 如果没有找到ACL（访问控制列表）配置，则允许任何操作。 
        allow.everyone.if.no.acl.found=false
        #超级管理员权限用户
        super.users=User:admin
        
        advertised.listeners=SASL_PLAINTEXT://192.168.40.150:9091bash
        ```
    6. 设置zookeeper的环境变量或JVM启动参数
        
        ```bash
        export KAFKA_OPTS=-Djava.security.auth.login.config=/usr/local/etc/kafka/config/zookeeper_jaas.conf
        ```
    7. 设置kafka的环境变量或JVM启动参数
        
        ```bash
        export KAFKA_OPTS=-Djava.security.auth.login.config=/usr/local/etc/kafka/config/kafka_server_jaas.conf
        ```
    8. 启动zookeeper和kafka
    9. (可选)如果要用kafka自带的命令来启动producer和consumer，则需要额外配置
        1. 配置producer和consumer所需认证信息，有两种方式
            1. 方式一：修改对应的properties文件
                1. producer的sasl配置：修改producer.properties文件，新增以下内容
                    
                    ```bash
                    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin";
                    security.protocol=SASL_PLAINTEXT
                    sasl.mechanism=PLAIN
                    ```
                3. consumer的sasl配置:修改consumer.properties文件，新增以下内容
                
                    ```bash
                    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin";
                    security.protocol=SASL_PLAINTEXT
                    sasl.mechanism=PLAIN
                    ```
            2. 方式二：设置环境变量
                
                ```bash
                export KAFKA_OPTS= -Djava.security.auth.login.config=/usr/local/etc/kafka/config/kafka_server_jaas.conf
                ```
        2. 启动kafka console producer
            
            ```bash
            kafka-console-producer --broker-list 192.168.40.150:9091 --topic testTopic  --producer.config  .../config/producer.properties
            ```
        4. 启动kafka console consumer
            
            ```bash
            kafka-console-consumer --bootstrap-server  192.168.40.150:9091 --topic testTopic --consumer.config .../config/consumer.properties
            ```
            
# 三 基础

## 1 架构
## 2 核心API
Kafka有四个核心的API:
1. The `Producer` API 允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。
2. The `Consumer` API 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。
3. The `Streams` API 允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。
4. The `Connector` API 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。

## 3 生产者
## 4 消费者

### 4.2 重复消费
先看看消费的几种处理逻辑和可能导致的问题：
1. 消费者从节点读取到数据后处理完业务再去修改偏移量 这样可以确保数据不会丢失， 但是有可能出现重复消费， 在后续修改偏移量的时候可能失败(比如程序down掉)
2. 消费者从节点读取到数据时顺便修改偏移量，这样可以确保不会重复消费， 但是业务可能处理失败， 导致数据丢失

### 4.1 消费者组
简单的说，是一组消费者共同消费一个或者多个topic, 当然某个消费者消费的是一个或者多个分区内的消息。
为什么有消费者，又要消费者组？消费者消费消息，需要订阅某个 topic, 消费者组共同消费一个或者多个 topic，这样可以的效果是：
1. 可拓展：新加入一个消费者，可以承担部分任务，减轻其他消费者负担；同理，减少一个消费者，再重新给消费者分配消息。这种分配机制，在 kafka 系统中称之为：Rebalance，动态的调整。
    1. 那么什么时候会 Rebalance：
        1. 消费者数目的变化
        2. topic 的变化
        3. 分区的变化
    2. Rebalance 有利有弊，利：可拓展，容错；弊：Rebalance 比较耗性能，某一个时刻会停止消费消息。
2. 容错：

多个消费者组：(todo)

## 5 消息
包含：
1. key/value:key和value是可选的，没有使用限制

## 6 topics
### 分区日志
日志中的 partition（分区）有以下几个用途：
1. 第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可能有多个分区，因此可以处理无限量的数据。
2. 第二，可以作为并行的单元集

### 分布式
每一个分区都会在已配置的服务器上进行备份，确保容错性。

每个分区都有一台 server 作为 “leader”，零台或者多台server作为 follwers 。leader server 处理一切对 partition （分区）的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers 中的一台服务器会自动成为新的 leader。每台 server 都会成为某些分区的 leader 和某些分区的 follower，因此集群的负载是平衡的。



## 7 认证
KAFKA使用JAVA认证和授权服务（JAAS,Java Authentication and Authorization Service）进行SASL配置，Java早期的安全框架强调的是通过验证代码的来源和作者，保护用户避免受到下载下来的代码的攻击。JAAS强调的是通过验证谁在运行代码以及他/她的权限来保护系统免受用户的攻击。