# 6.WebCrawler

# 一 概述
## 3 常识
### 3.1 Headless Browser
无头浏览器对于爬虫来说，是很重要的工具。相对于一般浏览器来说，节省了GUI所必须消耗的大量内存，给多线程、进程并行提供了方便。而爬虫碰到需要运行js代码时，它可以作为兜底工具。

除了Headless Browser，能达到同样作用的还有[selenium](https://www.selenium.dev/)和[Puppeteer](https://github.com/puppeteer/puppeteer)

# 三 基础

## 1 分类
### 字体反爬
通过自定义字体来自定义字符与渲染图形的映射。比如，字符 1 实际渲染的是 9，那么如果 HTML 中的数字是 111，实际显示就是 999。

# 五 经验
## 1 常见问题
日志：详细的日志可以帮助分析问题，改进不足以及恢复数据等。
错误处理：爬虫的天然属性就是随时可能无法工作，完善的错误处理和报警机制是必须的。
重试机制：很多接口会报错，需要有一定的重试机制。
数据校验：每一步获取到的数据都需要校验有效性，否则很容易在数据库中写入无效数据。
人工干预：有些环节比如 OCR 的准确率是无法做到 100% 的，要考虑到失败的情况，一旦 OCR 识别失败，需要引入人工干预流程。
IP 池：很多接口会限制 IP 的访问频率，这个时候要挂 IP 池。